---
layout: default
title: "PWM"
subtitle: Policy Learning with Large World Models
css: "/css/pwm.css"
meta-title: "PWM: Policy Learning with Large World Models"
datacampcourse: true
---

<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description" content="PWM: Policy Learning with Large World Models">
    <meta name="keywords" content="Reinforcement Learning, Robot Control, World Models">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>PWM</title>

    <!-- Google Tag Manager -->
    <script>(function (w, d, s, l, i) {
            w[l] = w[l] || []; w[l].push({
                'gtm.start':
                    new Date().getTime(), event: 'gtm.js'
            }); var f = d.getElementsByTagName(s)[0],
                j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
                    'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
        })(window, document, 'script', 'dataLayer', 'GTM-5VSL39R9');</script>
    <!-- End Google Tag Manager -->

    <script>
        function updateSingleVideo() {
            var demo = document.getElementById("single-menu-demos").value;
            var task = document.getElementById("single-menu-tasks").value;
            var inst = document.getElementById("single-menu-instances").value;

            console.log("single", demo, task, inst)

            var video = document.getElementById("multi-task-result-video");
            video.src = "media/results/sim_rollouts/" +
                "n" +
                demo +
                "-" +
                task +
                "-" +
                inst +
                ".mp4"
            video.playbackRate = 1.75;
            video.play();
        }

        function updateQpredVideo() {
            var task = document.getElementById("single-menu-qpred").value;

            console.log("qpred", task)

            var video = document.getElementById("q-pred-video");
            video.src = "media/results/qpred/" +
                task +
                ".mp4"
            video.playbackRate = 1.75;
            video.play();
        }

    </script>

    <script>
        document.addEventListener('DOMContentLoaded', function () {
            var video = document.getElementById('myVideo');
            video.addEventListener('loadedmetadata', function () {
                var aspectRatio = (video.videoHeight / video.videoWidth) * 100;
                var videoContainer = video.parentElement;
                videoContainer.style.paddingBottom = aspectRatio + '%';
            });
        });
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <link rel="stylesheet" href="./css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="./js/pwm.js"></script>
</head>

<body onload="updateSingleVideo(); updateQpredVideo();">


    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column is-three-quarters">
                        <div class="has-text-centered">
                            <h1 class="title is-1 publication-title">PWM: Policy Learning with Large World Models</h1>
                            <!-- <h3 class="title is-4 conference-authors"><a target="_blank"
                                href="https://www.robot-learning.org/">NeurIPS
                                2024 Submission</a></h3> -->
                            <div class="is-size-5 publication-authors">
                                <span class="author-block">
                                    <span class="author-block">
                                        <a target="_blank" href="https://www.imgeorgiev.com/">Ignat
                                            Georgiev</a><sup>1</sup>,</span>
                                    <span class="author-block">
                                        <a target="_blank" href="https://varungiridhar.github.io/">Varun
                                            Giridhar</a><sup>1</sup>,</span>
                                    <span class="author-block">
                                        <a target="_blank" href="https://www.nicklashansen.com/">Nicklas
                                            Hansen</a><sup>2</sup>,</span>
                                    <span class="author-block">
                                        <a target="_blank" href="https://animesh.garg.tech/">Animesh Garg</a><sup>1,
                                            3</sup>
                                    </span>
                            </div>

                            <div class="is-size-5 publication-authors">
                                <span class="author-block"><sup>1</sup>Georgia Institute of Technology,</span>
                                <span class="author-block"><sup>2</sup>UC San Diego,</span>
                                <span class="author-block"><sup>3</sup>Nvidia</span>
                            </div>

                            <div class="column has-text-centered">
                                <div class="publication-links">
                                    <!-- PDF Link. -->
                                    <!-- <span class="link-block">
                                    <a target="_blank" href="https://openreview.net/forum?id=VQOoHBRbpC"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span> -->

                                    <!-- Arxiv Link. -->
                                    <span class="link-block">
                                        <a target="_blank" href="TODO"
                                            class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon">
                                                <i class="fas fa-file"></i>
                                            </span>
                                            <span>ArXiv</span>
                                        </a>
                                    </span>

                                    <!-- Video Link. -->
                                    <span class="link-block">
                                        <a target="_blank" href="https://youtu.be/RulQmghf6BI"
                                            class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon">
                                                <i class="fab fa-youtube"></i>
                                            </span>
                                            <span>Video</span>
                                        </a>
                                    </span>

                                    <!-- Talk Link.
                <span class="link-block">
                  <a target="_blank" href="https://youtu.be/QcuXwmQgurE"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-chalkboard-teacher"></i>
                    </span>
                    <span>Talk</span>
                  </a>
                </span> -->


                                    <!-- Colab Link. -->
                                    <!-- <span class="link-block">
                  <a target="_blank"
                    href="https://colab.research.google.com/drive/1HAqemP4cE81SQ6QO1-N85j5bF4C0qLs0?usp=sharing"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fa fa-book" aria-hidden="true"></i>
                    </span>
                    <span>Colab</span>
                  </a>
                </span> -->

                                    <!-- Code Link. -->
                                    <span class="link-block">
                                        <a target="_blank" href="https://github.com/imgeorgiev/PWM"
                                            class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon">
                                                <i class="fab fa-github"></i>
                                            </span>
                                            <span>Code</span>
                                        </a>
                                    </span>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Abstract. -->
    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-two-thirds">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        Reinforcement Learning (RL) has achieved impressive results on complex tasks but struggles in
                        multi-task settings with different embodiments. World models offer scalability by learning a
                        simulation of the environment, yet they often rely on inefficient gradient-free optimization
                        methods. We introduce Policy learning with large World Models (PWM), a novel model-based RL
                        algorithm that learns continuous control policies from large multi-task world models. By
                        pre-training the world model on offline data and using it for first-order gradient policy
                        learning, PWM effectively solves tasks with up to 152 action dimensions and outperforms methods
                        using ground-truth dynamics. Additionally, PWM scales to an 80-task setting, achieving up to
                        27% higher rewards than existing baselines without the need for expensive online planning.
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Paper video. -->
    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-two-thirds">
                    <h2 class="title is-3">Video</h2>
                    <div class="publication-video">
                        <iframe
                            src="https://www.youtube.com/embed/RulQmghf6BI?modestbranding=1&autohide=1&showinfo=0&controls=1"
                            frameborder="0" allow="encrypted-media" allowfullscreen></iframe>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Method overview</h2>
                    <div class="video-container">
                        <video id="wm-animation" autoplay muted loop playsinline>
                            <source src="https://policy-world-model.github.io/media/wm-animation.mp4" type="video/mp4">
                        </video>
                    </div>

                    <br>
                    We introduce Policy learning with large World Models (PWM), a novel Model-Based RL (MBRL) algorithm
                    and framework aimed at deriving effective continuous control policies from large, multi-task world
                    models. We utilize pre-trained TD-MPC2 world models to efficiently learn control policies with FoG
                    in &lt; 10m per task. Our empirical evaluations on complex locomotion tasks indicate that PWM not
                    only achieves higher reward than baselines but also outperforms methods that use ground-truth
                    simulation dynamics. </h2>
                </div>
            </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-two-thirds">
                    <div class="columns is-centered is-vcentered">
                        <div class="column is-narrow">
                            <img src="https://policy-world-model.github.io/media/teaser_results.png"
                                alt="PWM teaser results" />
                        </div>
                    </div>
                    <p>
                        We evaluate PWM on high-dimensional continuous control tasks <b>(left figure)</b> and find that
                        it
                        not only outperforms model-free baselines SAC and PPO but also achieves higher rewards than
                        SHAC, a
                        method using the dynamics and reward function of the simulator directly. In an 80-task setting
                        <b>(right figure)</b> using a large 48M-parameter world model, PWM is able to consistently
                        outperform TD-MPC2, an MBRL method that uses the same world model, without the need for online
                        planning.
                    </p>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-widescreen">
            <div class="columns is-centered has-text-centered">
                <div class="column is-full">
                    <h2 class="title is-3"><span class="dperact">Single-task results</span></h2>
                    <div class="video-container" style="padding-top: 20%;">
                        <video id="dflex" autoplay muted loop playsinline>
                            <source src="https://policy-world-model.github.io/media/dflex.mp4" type="video/mp4">
                        </video>
                    </div>
                    <br>
                    <div class="columns is-centered is-vcentered">
                        <div class="column is-narrow">
                            <img src="https://policy-world-model.github.io/media/dflex_results_agg.png"
                                alt="agg results" class="column is-two-thirds" />
                        </div>
                    </div>
                    <p>
                        The figure shows 50% IQM with solid lines, mean with dashed lines, and 95% CI over all 5 tasks
                        and 5 random seeds. PWM is able to achieve a higher reward than model-free baselines PPO and
                        SAC, TD-MPC2, which uses the same world model as PWM and SHAC which uses the ground-truth
                        dynamics and reward functions of the simulator. These results indicate that well-regularized
                        world models can smooth out the optimization landscape, allowing for better first-order gradient
                        optimization.
                    </p>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-widescreen">
            <div class="columns is-centered has-text-centered">
                <div class="column is-full">
                    <h2 class="title is-3"><span class="dperact">Multi-task results</span></h2>
                    <div class="media-grid">
                        <video
                            src="https://policy-world-model.github.io/media/pwm-videos/dmcontrol-formatted/fish-swim.mp4"
                            width="128" height="128" autoplay muted loop style="height: auto;"></video>
                        <video
                            src="https://policy-world-model.github.io/media/pwm-videos/metaworld-formatted/mw-coffee-button.mp4"
                            width="128" height="128" autoplay muted loop style="height: auto;"></video>
                        <video
                            src="https://policy-world-model.github.io/media/pwm-videos/dmcontrol-formatted/cheetah-run-back.mp4"
                            width="128" height="128" autoplay muted loop style="height: auto;"></video>
                        <video
                            src="https://policy-world-model.github.io/media/pwm-videos/metaworld-formatted/mw-drawer-close.mp4"
                            width="128" height="128" autoplay muted loop style="height: auto;"></video>
                        <video
                            src="https://policy-world-model.github.io/media/pwm-videos/dmcontrol-formatted/walker-run.mp4"
                            width="128" height="128" autoplay muted loop style="height: auto;"></video>
                        <video
                            src="https://policy-world-model.github.io/media/pwm-videos/metaworld-formatted/mw-hammer.mp4"
                            width="128" height="128" autoplay muted loop style="height: auto;"></video>
                        <video
                            src="https://policy-world-model.github.io/media/pwm-videos/dmcontrol-formatted/walker-walk-backwards.mp4"
                            width="128" height="128" autoplay muted loop style="height: auto;"></video>
                        <video
                            src="https://policy-world-model.github.io/media/pwm-videos/metaworld-formatted/mw-push-wall.mp4"
                            width="128" height="128" autoplay muted loop style="height: auto;"></video>
                        <video
                            src="https://policy-world-model.github.io/media/pwm-videos/dmcontrol-formatted/walker-walk.mp4"
                            width="128" height="128" autoplay muted loop style="height: auto;"></video>
                        <video
                            src="https://policy-world-model.github.io/media/pwm-videos/metaworld-formatted/mw-lever-pull.mp4"
                            width="128" height="128" autoplay muted loop style="height: auto;"></video>
                        <!-- Repeat for all media -->
                    </div>
                    <div class="columns is-centered is-vcentered">
                        <div class="column is-narrow">
                            <img src="https://policy-world-model.github.io/media/mutlitask_full.png"
                                alt="Full multi-task results" />
                        </div>
                    </div>
                    <p>
                        The figure shows the performance of PWM and TD-MPC2 on 30 and 80 multi-task benchmarks with
                        results over 10 random seeds. PWM is able to outperform TD-MPC2 while using the same world model
                        without any form of online planning, making it the more scalable approach to large world models.
                        The right figure compares PWM, a multi-task policy, with single-task experts SAC and DreamerV3.
                        It is impressive that PWM is able to match their performance while being multi-task and only
                        trained on offline data.
                    </p>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-widescreen">
            <div class="columns is-centered has-text-centered">
                <div class="column is-full">
                    <p>
                        We strongly believe that increasingly large world models of billions of parameters and policy
                        learning strategies such as PWM can unlock dexterous robotics at scale.
                    </p>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-widescreen">
            <h2 class="title is-3">Citation</h2>
            <div class="columns is-centered has-text-centered">
                <p>
                    If you find our work useful, please consider citing the paper as follows:
                </p>
                <div id="bibtex-text" class="bibtexsection"
                    onClick="window.getSelection().selectAllChildren(document.getElementById('bibtex-text'));">
                    @misc{georgiev2024pwm,
                    title={PWM: Policy Learning with Large World Models},
                    author={Ignat Georgiev, Varun Giridha, Nicklas Hansen, and Animesh Garg},
                    eprint={2405.18418}, <!--TODO -->
                    archivePrefix={arXiv},
                    primaryClass={cs.LG},
                    year={2024}
                    }
                </div>
            </div>
        </div>
    </section>


</body>

</html>